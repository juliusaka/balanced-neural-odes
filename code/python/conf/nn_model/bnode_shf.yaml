defaults:
  - latent_ode_base
  - _self_

network:
  n_linear_layers: 4
  linear_hidden_dim: 128
  hidden_dim_output_nn: 128
  activation: torch.nn.ELU
  controls_to_decoder: true
  lat_states_dim: 16
  lat_parameters_dim: 16
  lat_controls_dim: 16
  lat_ode_type: 'variance_constant' 
  koopman_mpc_mode: false 
  lat_state_mu_independent: true
  
training:
  pre_train: false
  load_pretrained_model: false
  load_trained_model_for_test: false
  batch_size_test: 256

  pre_trained_model_seq_len: null
  path_pretrained_model: ''
  path_trained_model: ''

  test_save_internal_variables: false

  weight_decay_override: 1e-5
  early_stopping_threshold_mode_override: abs
  early_stopping_threshold_override: 0.00001 # 0.0001 would be 1% error, so take 0.1%
  beta_start_override: 0.1
  alpha_mu_override: 1.0

  reload_optimizer_override: false
  use_adjoint_override: false
  solver_rtol_override: 1e-3
  solver_atol_override: 1e-4
  beta1_adam_override: 0.8
  beta2_adam_override: 0.99
  clip_grad_norm_override: 1.0

  initialization_type: null
  initialization_type_ode: null # move_eigvals_net
  initialization_type_ode_matrix: null # move_eigvals_matrix

  main_training:

  # pre training with 30 steps
  - batch_size: 800
    solver: rk4
    lr_start: 1e-3
    max_epochs: 500
    early_stopping_patience: 10
    load_seq_len: null
    seq_len_train: 10
    evaluate_at_control_times: false
    # break_after_loss_of: 0.1

  # # increase seq len to 250
  - batch_size: 400
    solver: rk4
    lr_start: 1e-3
    max_epochs: 500
    early_stopping_patience: 50
    seq_len_train: 250 
    seq_len_increase_in_batches: 100
    seq_len_increase_abort_after_n_stable_epochs: 10
    evaluate_at_control_times: false
    activate_deterministic_mode_after_this_phase: false

  # increase to 400
  - batch_size: 128
    solver: rk4
    lr_start: 1e-3
    max_epochs: 1000
    early_stopping_patience: 50
    seq_len_train: 400 
    seq_len_increase_in_batches: 100
    seq_len_increase_abort_after_n_stable_epochs: 10
    evaluate_at_control_times: false